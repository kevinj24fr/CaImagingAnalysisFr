% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/advanced_deep_learning.R
\name{transformer_spike_inference}
\alias{transformer_spike_inference}
\title{Transformer-Based Spike Inference}
\usage{
transformer_spike_inference(
  traces,
  model_path = NULL,
  sequence_length = 100,
  n_heads = 8,
  n_layers = 6,
  ...
)
}
\arguments{
\item{traces}{Matrix of calcium traces (cells x time)}

\item{model_path}{Path to pretrained transformer model (optional)}

\item{sequence_length}{Length of input sequences (default: 100)}

\item{n_heads}{Number of attention heads (default: 8)}

\item{n_layers}{Number of transformer layers (default: 6)}

\item{...}{Additional arguments}
}
\value{
Spike predictions and attention weights
}
\description{
Use transformer models for spike inference with attention mechanisms.
}
