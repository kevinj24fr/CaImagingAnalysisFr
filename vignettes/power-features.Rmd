---
title: "Power Features of CaImagingAnalysisFr: Advanced Calcium Imaging Analytics"
author: "Calcium Team"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Power Features of CaImagingAnalysisFr}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.width = 8,
  fig.height = 6
)
library(CaImagingAnalysisFr)
```

# Introduction

`CaImagingAnalysisFr` is not just a basic calcium imaging toolkit—it is a **comprehensive, professional, and state-of-the-art platform** for advanced analysis, quality control, and discovery in neuroscience. This vignette highlights the most powerful features that set it apart from other packages.

# 1. Automated Cell Segmentation & ROI Extraction

Extracting cells and ROIs from raw imaging data is a critical first step. This package provides robust, automated segmentation using multiple algorithms:

```{r segmentation}
# Simulate a realistic imaging matrix with bright "cells" on noisy background
set.seed(123)
raw_img <- array(rnorm(100*100*200, sd = 0.1), dim = c(100, 100, 200))

# Add bright spots (simulated cells) at random locations
n_cells <- 15
for (i in 1:n_cells) {
  # Random cell center
  center_x <- sample(20:80, 1)
  center_y <- sample(20:80, 1)
  
  # Add bright spot with Gaussian profile
  for (x in max(1, center_x-5):min(100, center_x+5)) {
    for (y in max(1, center_y-5):min(100, center_y+5)) {
      distance <- sqrt((x - center_x)^2 + (y - center_y)^2)
      if (distance <= 5) {
        intensity <- 2 * exp(-distance^2 / 8)  # Gaussian profile
        raw_img[x, y, ] <- raw_img[x, y, ] + intensity
      }
    }
  }
}

# Automated segmentation (Suite2p-style, base R)
seg <- segment_cells(raw_img, method = "suite2p", min_size = 20, verbose = FALSE)
str(seg)

# ROI quality control
qc <- roi_quality_control(seg$rois, raw_img)
print(qc)

# --- Advanced: Visualize segmentation overlay and benchmark quality ---
props <- region_properties(seg$rois, apply(raw_img, c(1,2), mean))
plot_segmentation_overlay(apply(raw_img, c(1,2), mean), seg$rois, property = "area", props = props, main = "Segmentation Overlay (color: area)")
bench <- benchmark_segmentation_quality(props)
print(bench)
```

## Interpreting Segmentation Quality Metrics

- **Number of ROIs (`n_roi`)**: Should roughly match the expected number of cells. Too high may indicate over-segmentation (splitting cells or noise), too low may indicate missed cells.
- **Area**: Mean/median area should be consistent with expected cell size (in pixels). Large variance may indicate inconsistent segmentation.
- **Eccentricity**: Ranges from 0 (perfect circle) to 1 (line). Most cells should have moderate eccentricity (e.g., 0.3–0.8). Very high values may indicate elongated or merged ROIs.
- **Solidity**: Ratio of area to convex hull area. Values near 1 indicate compact, convex shapes (good for cells). Low values may indicate irregular or fragmented ROIs.
- **Jaccard (if ground truth)**: Measures overlap with ground truth. Values near 1 are ideal; values <0.5 may indicate poor segmentation.

Use these metrics to tune segmentation parameters and assess the reliability of automated cell detection in your data.

# 2. Deep Learning Spike Inference (Base R)

Leverage advanced spike inference without Python dependencies:

```{r deep-spike}
# Simulate a calcium trace
trace <- rnorm(500)

# Deep learning spike inference (base R implementation)
deep_spikes <- infer_spikes(trace, method = "deep", verbose = FALSE)
head(deep_spikes)
```

# 3. Batch Effect Correction

Correct for batch effects across experiments or imaging sessions:

```{r batch-correction}
# Simulate batch-labeled data
mat <- matrix(rnorm(3000), nrow = 100, ncol = 30)
batch <- rep(1:3, each = 10)
corrected <- batch_correction(mat, batch = batch, method = "deep")
str(corrected)
```

# 4. Advanced Denoising: NMF, ICA, Wavelet

Extract clean signals and components using modern matrix factorization and signal processing:

```{r denoising}
# NMF decomposition
nmf_res <- nmf_decompose(abs(mat), n_components = 3)
str(nmf_res)

# ICA decomposition
ica_res <- ica_decompose(mat, n_components = 3)
str(ica_res)

# Wavelet denoising
denoised <- wavelet_denoise(trace)
str(denoised)
```

# 5. Dynamic Network & Causality Analysis

Go beyond correlation: infer functional networks, causality, and community structure:

```{r network}
# Functional connectivity
fc <- functional_connectivity(mat, method = "correlation", threshold = 0.3)
str(fc)

# Granger causality between two cells
gc <- granger_causality(mat[,1], mat[,2], max_lag = 2)
gc

# Community detection
comm <- community_detection(fc$connectivity_matrix, method = "louvain")
str(comm)
```

# 6. Unsupervised Learning & Anomaly Detection

Discover hidden structure and outliers in your data:

```{r unsupervised}
# UMAP dimensionality reduction
umap_res <- umap_reduce(mat, n_components = 2)
plot(umap_res, main = "UMAP Embedding")

# K-means clustering
clust <- kmeans_clustering(mat, centers = 3)
table(clust$cluster)

# Anomaly detection (base R)
anom <- anomaly_detection(mat)
summary(anom)
```

# 7. Bayesian Modeling & Model Comparison

Perform robust Bayesian inference and compare models:

```{r bayesian}
# Bayesian spike inference
bayes_spikes <- bayesian_spike_inference(trace)
str(bayes_spikes)

# Model comparison - create models with correct format
model1 <- list(
  spikes = bayesian_spike_inference(trace, n_samples = 500)$posterior_spikes,
  log_likelihood = -100,
  aic = 200,
  bic = 250,
  dic = 180
)
model2 <- list(
  spikes = bayesian_spike_inference(trace + rnorm(length(trace), 0, 0.1), n_samples = 500)$posterior_spikes,
  log_likelihood = -110,
  aic = 220,
  bic = 270,
  dic = 200
)
comp <- bayesian_model_comparison(list(model1, model2))
str(comp)
```

# 8. Automated Reporting & Interactive QC

Generate interactive reports and launch QC dashboards:

```{r reporting, eval = FALSE}
# Generate a comprehensive HTML report
generate_report(raw_data = mat, corrected_data = corrected)

# Launch interactive QC dashboard
launch_interactive_viewer(mat)
```

# 9. Data Curation & Metadata Handling

Automate data curation and ensure reproducibility:

```{r curation}
# Curate and validate metadata
data <- curate_data(mat, metadata = data.frame(batch = batch))
str(data)
```

# 10. End-to-End Professional Workflow

Combine all features for a seamless, reproducible, and publication-ready analysis:

```{r pipeline, eval = FALSE}
# Note: This requires the 'targets' package
# Install with: install.packages('targets')
pipeline <- calcium_pipeline(
  n_cells = 10,
  n_time = 1000,
  correction_method = "modern",
  spike_method = "deep",
  normalize = TRUE
)
str(pipeline)
```

# Conclusion

`CaImagingAnalysisFr` empowers neuroscientists with a **professional, robust, and cutting-edge toolkit** for every stage of calcium imaging analysis—from raw data to publication. Explore the documentation and function references for even more advanced options! 